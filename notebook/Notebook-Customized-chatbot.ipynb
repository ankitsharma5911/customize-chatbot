{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hMahgI9rFrVP"
   },
   "outputs": [],
   "source": [
    "!pip install -q groq langchain_community langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nyNIbjKvFscj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pRRtW9C4FsZk"
   },
   "outputs": [],
   "source": [
    "groq_api_key=\"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\"  # Replace with your actual API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bYblpiSlFsVV"
   },
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    api_key =groq_api_key,\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xQqFiYMxFsTA"
   },
   "outputs": [],
   "source": [
    "custom_prompt_template_for_chatbot = \"\"\"\n",
    "You are a knowledgeable assistant specializing in Data Science and Artificial Intelligence (AI).\n",
    "\n",
    "Your primary objective is to assist students by providing clear, concise, and accurate answers to their questions specifically related to Data Science and AI. This includes, but is not limited to, the following topics:\n",
    "- Programming languages and tools: Python, SQL (MySQL, SQLite, MongoDB)\n",
    "- Data visualization tools: Power BI, Tableau\n",
    "- Statistical concepts and methodologies\n",
    "- Machine Learning (ML) techniques and frameworks\n",
    "- MLFlow for managing machine learning workflows\n",
    "- Containerization with Docker\n",
    "- Deep Learning concepts and frameworks\n",
    "- Natural Language Processing (NLP)\n",
    "- Generative AI technologies\n",
    "- Skills required for a career in Data Science and AI\n",
    "\n",
    "When responding, ensure that your answers are focused and straightforward, avoiding unnecessary details. If users ask complex questions, break down your responses into manageable parts and provide step-by-step explanations when needed.\n",
    "\n",
    "Always be polite and encouraging, ensuring that you provide accurate information at all times.\n",
    "\n",
    "If a question is asked that falls outside the realm of Data Science and AI or does not relate to the topics mentioned above, respond with a polite message indicating that the question is unrelated. For example: \"I'm sorry, but that topic is outside the scope of Data Science and AI. I'm unable to provide an answer.\"\n",
    "\n",
    "Remember previous exchanges in the conversation to provide better context for your responses.\n",
    "\n",
    "History: {history}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lbolIiehGGve"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankit\\AppData\\Local\\Temp\\ipykernel_11408\\653084327.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(input_key=\"question\", memory_key=\"history\")\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=custom_prompt_template_for_chatbot,\n",
    "                            input_variables=['history','context', 'question'])\n",
    "\n",
    "memory = ConversationBufferMemory(input_key=\"question\", memory_key=\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8AIPX9XxK6e7"
   },
   "outputs": [],
   "source": [
    "# Function to format output in Markdown\n",
    "def format_output(response):\n",
    "    if isinstance(response, str):\n",
    "        # Check if the response contains code (you can customize this check)\n",
    "        if response.startswith(\"``````\"):\n",
    "            return response  # Return as is if it's already in code block\n",
    "        else:\n",
    "            # Format as markdown for theoretical responses\n",
    "            formatted_response = f\"# Response\\n\\n{response}\"\n",
    "            return formatted_response\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VGXuobIsGUI9"
   },
   "outputs": [],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    response = chain.invoke({\"history\": memory, \"context\": \"\", \"question\": question})\n",
    "    return format_output(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9Up-jyB4zwLA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Here's a step-by-step Python code to train a linear regression model from data preparation to making predictions:\\n\\n```python\\n# Import necessary libraries\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn import metrics\\nimport numpy as np\\n\\n# Load the dataset (replace 'data.csv' with your dataset file)\\ndata = pd.read_csv('data.csv')\\n\\n# Let's assume we have two columns: 'feature' and 'target'\\n# We'll use 'feature' to predict 'target'\\n\\n# Define the feature and target variables\\nX = data[['feature']]\\ny = data['target']\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\\n\\n# Create a Linear Regression model\\nmodel = LinearRegression()\\n\\n# Train the model using the training sets\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions using the testing set\\ny_pred = model.predict(X_test)\\n\\n# Print the coefficients\\nprint('Intercept:', model.intercept_)\\nprint('Slope:', model.coef_)\\n\\n# Evaluate the model\\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\\n\\n# Use the model to make a prediction\\nnew_data = [[10]]  # replace 10 with your new data point\\nnew_prediction = model.predict(new_data)\\nprint('Prediction:', new_prediction)\\n```\\n\\nThis code covers the following steps:\\n\\n1. Data loading\\n2. Data splitting into training and testing sets\\n3. Model creation and training\\n4. Making predictions\\n5. Evaluating the model\\n6. Using the model to make a new prediction\\n\\nMake sure to replace `'data.csv'` with your actual dataset file and adjust the column names (`'feature'` and `'target'`) according to your dataset.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 431, 'prompt_tokens': 353, 'total_tokens': 784, 'completion_time': 1.567272727, 'prompt_time': 0.040388282, 'queue_time': 0.027015311, 'total_time': 1.607661009}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_4196e754db', 'finish_reason': 'stop', 'logprobs': None} id='run-10aa9aee-060d-4f76-a940-9defffba5d1c-0' usage_metadata={'input_tokens': 353, 'output_tokens': 431, 'total_tokens': 784}\n"
     ]
    }
   ],
   "source": [
    "question = \"write a python code to train linear regression model from taking data till predictions\"\n",
    "response = invoke_chain(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a step-by-step Python code to train a linear regression model from data preparation to making predictions:\n",
      "\n",
      "```python\n",
      "# Import necessary libraries\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn import metrics\n",
      "import numpy as np\n",
      "\n",
      "# Load the dataset (replace 'data.csv' with your dataset file)\n",
      "data = pd.read_csv('data.csv')\n",
      "\n",
      "# Let's assume we have two columns: 'feature' and 'target'\n",
      "# We'll use 'feature' to predict 'target'\n",
      "\n",
      "# Define the feature and target variables\n",
      "X = data[['feature']]\n",
      "y = data['target']\n",
      "\n",
      "# Split the data into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
      "\n",
      "# Create a Linear Regression model\n",
      "model = LinearRegression()\n",
      "\n",
      "# Train the model using the training sets\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Make predictions using the testing set\n",
      "y_pred = model.predict(X_test)\n",
      "\n",
      "# Print the coefficients\n",
      "print('Intercept:', model.intercept_)\n",
      "print('Slope:', model.coef_)\n",
      "\n",
      "# Evaluate the model\n",
      "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
      "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
      "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
      "\n",
      "# Use the model to make a prediction\n",
      "new_data = [[10]]  # replace 10 with your new data point\n",
      "new_prediction = model.predict(new_data)\n",
      "print('Prediction:', new_prediction)\n",
      "```\n",
      "\n",
      "This code covers the following steps:\n",
      "\n",
      "1. Data loading\n",
      "2. Data splitting into training and testing sets\n",
      "3. Model creation and training\n",
      "4. Making predictions\n",
      "5. Evaluating the model\n",
      "6. Using the model to make a new prediction\n",
      "\n",
      "Make sure to replace `'data.csv'` with your actual dataset file and adjust the column names (`'feature'` and `'target'`) according to your dataset.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ga82r2aBofnV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I'm excited to help you with your Data Science and AI questions. What would you like to know or discuss today?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 339, 'total_tokens': 364, 'completion_time': 0.090909091, 'prompt_time': 0.038117389, 'queue_time': 0.149600641, 'total_time': 0.12902648}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_4196e754db', 'finish_reason': 'stop', 'logprobs': None} id='run-9f90a9e2-119e-47b2-8072-c38f6fb77079-0' usage_metadata={'input_tokens': 339, 'output_tokens': 25, 'total_tokens': 364}\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"Ask a question (or type 'exit' to quit): \")\n",
    "    if question.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    response = invoke_chain(question)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNixWR3imGiPaPLD/71sALg",
   "mount_file_id": "1j2D-q6AWY1AXCSv7B-Qj5sEeiQeAzo9X",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
